{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ee39237",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14015f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, lfilter, welch\n",
    "from scipy import stats\n",
    "import mne\n",
    "from sklearn.utils import resample\n",
    "from mne.filter import filter_data\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split,cross_validate, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score,recall_score, f1_score, confusion_matrix, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b8be98",
   "metadata": {},
   "source": [
    "Summary file parsing to extract seizure start and end times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91af3f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_seizure_events_from_txt(folder_path):\n",
    "    \"\"\"\n",
    "    Parses all .txt summary files in a folder to extract seizure start/end times\n",
    "    for each corresponding .edf file.\n",
    "\n",
    "    \"\"\"\n",
    "    seizure_info = {}\n",
    "\n",
    "    txt_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "    if not txt_files:\n",
    "        raise FileNotFoundError(\"No .txt summary files found in the folder.\")\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        summary_file = os.path.join(folder_path, txt_file)\n",
    "        current_file = None\n",
    "        current_start = None\n",
    "\n",
    "        with open(summary_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "\n",
    "                if line.startswith(\"File Name:\"):\n",
    "                    current_file = line.split(\":\", 1)[1].strip()\n",
    "                    if current_file not in seizure_info:\n",
    "                        seizure_info[current_file] = []\n",
    "\n",
    "                elif line.startswith(\"Seizure Start Time:\"):\n",
    "                    current_start = int(line.split(\":\", 1)[1].strip().split()[0])\n",
    "\n",
    "                elif line.startswith(\"Seizure End Time:\") and current_start is not None:\n",
    "                    end_time = int(line.split(\":\", 1)[1].strip().split()[0])\n",
    "                    seizure_info[current_file].append((current_start, end_time))\n",
    "                    current_start = None \n",
    "\n",
    "    return seizure_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53420657",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3968377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_edf_with_seizures(edf_path, seizure_times, sampling_rate=256):\n",
    "    \"\"\"\n",
    "    Load EDF file and return data with seizure annotations.\n",
    "    Keeps only first occurrence of duplicate base channel names.\n",
    "    \"\"\"\n",
    "    raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
    "\n",
    "    base_names = [name.split('-')[0] + '-' + name.split('-')[1] if name.count('-') >= 2 else name for name in raw.ch_names]\n",
    "\n",
    "    seen = set()\n",
    "    keep = []\n",
    "    for i, name in enumerate(base_names):\n",
    "        if name not in seen:\n",
    "            seen.add(name)\n",
    "            keep.append(raw.ch_names[i])\n",
    "\n",
    "    raw.pick_channels(keep)\n",
    "\n",
    "    seizure_samples = [\n",
    "        (int(start * sampling_rate), int(end * sampling_rate))\n",
    "        for start, end in seizure_times\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        'raw': raw,\n",
    "        'seizure_samples': seizure_samples\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "079201da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_load_edf_with_seizures(data_folder):\n",
    "    \"\"\"\n",
    "    Loads all .edf files in a folder with their seizure annotations.\n",
    "\n",
    "    \"\"\"\n",
    "    seizure_info = extract_seizure_events_from_txt(data_folder)\n",
    "    loaded_data = {}\n",
    "\n",
    "    for fname in os.listdir(data_folder):\n",
    "        if fname.endswith('.edf') and fname in seizure_info:\n",
    "            edf_path = os.path.join(data_folder, fname)\n",
    "            seizure_times = seizure_info[fname]\n",
    "\n",
    "            try:\n",
    "                result = load_edf_with_seizures(edf_path, seizure_times)\n",
    "                loaded_data[fname] = result\n",
    "                print(f\"Loaded {fname} with {len(result['seizure_samples'])} seizure intervals\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {fname}: {e}\")\n",
    "\n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e509f4",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13260806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_file(raw, edf_filename, output_folder, selected_channels, seizure_windows):\n",
    "    \"\"\"\n",
    "    Preprocesses EEG and saves .npz with metadata.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    raw.pick_channels(selected_channels)\n",
    "    data = raw.get_data()\n",
    "    sfreq = raw.info['sfreq']\n",
    "\n",
    "\n",
    "    data = filter_data(data, sfreq=sfreq, l_freq=0.5, h_freq=25.0, verbose=False)\n",
    "\n",
    "    base_name = os.path.splitext(edf_filename)[0]\n",
    "    save_path = os.path.join(output_folder, f\"{base_name}_preprocessed.npz\")\n",
    "    np.savez(save_path,\n",
    "             data=data,\n",
    "             seizure_windows=np.array(seizure_windows, dtype=np.int32),\n",
    "             sampling_rate=sfreq,\n",
    "             channels=np.array(selected_channels),\n",
    "             file_name=edf_filename)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c7170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save(edf_folder):\n",
    "    \"\"\"\n",
    "    Batch preprocesses and saves all EDF files in folder.\n",
    "    Skips files missing required channels.\n",
    "    \"\"\"\n",
    "    output_folder = os.path.join(edf_folder, 'preprocessed')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    selected_channels = [\n",
    "        'FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1',\n",
    "        'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1',\n",
    "        'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2',\n",
    "        'FP2-F8', 'F8-T8',  'P8-O2',\n",
    "        'FZ-CZ', 'CZ-PZ'\n",
    "    ]\n",
    "\n",
    "    seizure_dict = extract_seizure_events_from_txt(edf_folder)\n",
    "\n",
    "    for fname in os.listdir(edf_folder):\n",
    "        if fname.endswith('.edf'):\n",
    "            edf_path = os.path.join(edf_folder, fname)\n",
    "            seizure_times = seizure_dict.get(fname, [])\n",
    "\n",
    "            try:\n",
    "                # Load with filtering of duplicate channels\n",
    "                data_obj = load_edf_with_seizures(edf_path, seizure_times)\n",
    "                raw = data_obj['raw']\n",
    "\n",
    "                # Check if all selected channels are present (after cleaning)\n",
    "                available_channels = set(raw.ch_names)\n",
    "                if not all(chan in available_channels for chan in selected_channels):\n",
    "                    print(f\"Skipping {fname}: missing expected channels.\")\n",
    "                    continue\n",
    "\n",
    "                # Now process and save\n",
    "                process_single_file(\n",
    "                    raw=raw,\n",
    "                    edf_filename=fname,\n",
    "                    output_folder=output_folder,\n",
    "                    selected_channels=selected_channels,\n",
    "                    seizure_windows=data_obj['seizure_samples']\n",
    "                )\n",
    "\n",
    "                base_name = os.path.splitext(fname)[0]\n",
    "                print(f\"Saved to: {os.path.join(output_folder, base_name + '_preprocessed.npz')}\\n\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {fname}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee4417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_and_label(eeg_data, seizure_windows, window_duration=2.0, sampling_rate=256, overlap=0.5):\n",
    "    \"\"\"\n",
    "    Segments EEG into overlapping windows and labels them\n",
    "    \"\"\"\n",
    "    window_size = int(window_duration*sampling_rate)\n",
    "    step_size = int(window_size*(1-overlap))\n",
    "    channels, total_samples = eeg_data.shape\n",
    "    X,y = [], []\n",
    "    for start in range(0, total_samples-window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        window = eeg_data[:, start:end]\n",
    "\n",
    "        label = 0\n",
    "        for sz_start, sz_end in seizure_windows:\n",
    "            if end > sz_start and start < sz_end:\n",
    "                label = 1\n",
    "                break\n",
    "        X.append(window) \n",
    "        y.append(label)\n",
    "\n",
    "    X = np.stack(X)\n",
    "    y = np.stack(y)\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68540407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_segment_preprocessed(folder_path):\n",
    "    \"\"\"\n",
    "    Segments all preprocessed .npz files in 'preprocessed/' subfolder\n",
    "    into 2s windows and labels them.\n",
    "    \"\"\"\n",
    "    preprocessed_folder = os.path.join(folder_path, 'preprocessed')\n",
    "    output_folder = os.path.join(folder_path, 'segmented')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for fname in os.listdir(preprocessed_folder):\n",
    "        if fname.endswith(\"_preprocessed.npz\"):\n",
    "            full_path = os.path.join(preprocessed_folder, fname)\n",
    "\n",
    "            try:\n",
    "                npz = np.load(full_path, allow_pickle=True)\n",
    "                eeg = npz['data']\n",
    "                sz_windows = npz[\"seizure_windows\"]\n",
    "                sfreq = int(npz['sampling_rate'])\n",
    "                file_name = str(npz['file_name'])\n",
    "                channels = list(npz['channels'])\n",
    "                X, y = segment_and_label(eeg_data=eeg,\n",
    "                         seizure_windows=sz_windows,\n",
    "                         window_duration=2.0,\n",
    "                         sampling_rate=sfreq,\n",
    "                         overlap=0.5)\n",
    "                base_name = fname.replace('_preprocessed.npz', '')\n",
    "                save_path = os.path.join(output_folder, f\"{base_name}_segmented.npz\")\n",
    "                np.savez(save_path,\n",
    "                         X=X,\n",
    "                         y=y,\n",
    "                         sampling_rate=sfreq,\n",
    "                         channels=channels,\n",
    "                         file_name=file_name)\n",
    "\n",
    "                print(f\"Segmented and saved: {save_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed on {fname}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e7c8b5",
   "metadata": {},
   "source": [
    "Concatenate all NPZ files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a02c5d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_segmented_dataset(folder_path):\n",
    "    \"\"\"\n",
    "    Loads and concatenates all segmented .npz files in a folder.\n",
    "    \"\"\"\n",
    "    X_list, y_list = [], []\n",
    "\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if fname.endswith('_segmented.npz'):\n",
    "            npz_path = os.path.join(folder_path, fname)\n",
    "            try:\n",
    "                npz = np.load(npz_path)\n",
    "                X = npz['X']\n",
    "                y = npz['y']\n",
    "                X_list.append(X)\n",
    "                y_list.append(y)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load {fname}: {e}\")\n",
    "\n",
    "    X_total = np.concatenate(X_list, axis=0)\n",
    "    y_total = np.concatenate(y_list, axis=0)\n",
    "\n",
    "    return X_total, y_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce3125",
   "metadata": {},
   "source": [
    "############ Calling The Functions ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a800f1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chb01_01.edf': [],\n",
       " 'chb01_02.edf': [],\n",
       " 'chb01_03.edf': [(2996, 3036)],\n",
       " 'chb01_04.edf': [(1467, 1494)],\n",
       " 'chb01_05.edf': [],\n",
       " 'chb01_06.edf': [],\n",
       " 'chb01_07.edf': [],\n",
       " 'chb01_08.edf': [],\n",
       " 'chb01_09.edf': [],\n",
       " 'chb01_10.edf': [],\n",
       " 'chb01_11.edf': [],\n",
       " 'chb01_12.edf': [],\n",
       " 'chb01_13.edf': [],\n",
       " 'chb01_14.edf': [],\n",
       " 'chb01_15.edf': [(1732, 1772)],\n",
       " 'chb01_16.edf': [(1015, 1066)],\n",
       " 'chb01_17.edf': [],\n",
       " 'chb01_18.edf': [(1720, 1810)],\n",
       " 'chb01_19.edf': [],\n",
       " 'chb01_20.edf': [],\n",
       " 'chb01_21.edf': [(327, 420)],\n",
       " 'chb01_22.edf': [],\n",
       " 'chb01_23.edf': [],\n",
       " 'chb01_24.edf': [],\n",
       " 'chb01_25.edf': [],\n",
       " 'chb01_26.edf': [(1862, 1963)],\n",
       " 'chb01_27.edf': [],\n",
       " 'chb01_29.edf': [],\n",
       " 'chb01_30.edf': [],\n",
       " 'chb01_31.edf': [],\n",
       " 'chb01_32.edf': [],\n",
       " 'chb01_33.edf': [],\n",
       " 'chb01_34.edf': [],\n",
       " 'chb01_36.edf': [],\n",
       " 'chb01_37.edf': [],\n",
       " 'chb01_38.edf': [],\n",
       " 'chb01_39.edf': [],\n",
       " 'chb01_40.edf': [],\n",
       " 'chb01_41.edf': [],\n",
       " 'chb01_42.edf': [],\n",
       " 'chb01_43.edf': [],\n",
       " 'chb01_46.edf': [],\n",
       " 'chb02_01.edf': [],\n",
       " 'chb02_02.edf': [],\n",
       " 'chb02_03.edf': [],\n",
       " 'chb02_04.edf': [],\n",
       " 'chb02_05.edf': [],\n",
       " 'chb02_06.edf': [],\n",
       " 'chb02_07.edf': [],\n",
       " 'chb02_08.edf': [],\n",
       " 'chb02_09.edf': [],\n",
       " 'chb02_10.edf': [],\n",
       " 'chb02_11.edf': [],\n",
       " 'chb02_12.edf': [],\n",
       " 'chb02_13.edf': [],\n",
       " 'chb02_14.edf': [],\n",
       " 'chb02_15.edf': [],\n",
       " 'chb02_16.edf': [(130, 212)],\n",
       " 'chb02_16+.edf': [(2972, 3053)],\n",
       " 'chb02_17.edf': [],\n",
       " 'chb02_18.edf': [],\n",
       " 'chb02_19.edf': [(3369, 3378)],\n",
       " 'chb02_20.edf': [],\n",
       " 'chb02_21.edf': [],\n",
       " 'chb02_22.edf': [],\n",
       " 'chb02_23.edf': [],\n",
       " 'chb02_24.edf': [],\n",
       " 'chb02_25.edf': [],\n",
       " 'chb02_26.edf': [],\n",
       " 'chb02_27.edf': [],\n",
       " 'chb02_28.edf': [],\n",
       " 'chb02_29.edf': [],\n",
       " 'chb02_30.edf': [],\n",
       " 'chb02_31.edf': [],\n",
       " 'chb02_32.edf': [],\n",
       " 'chb02_33.edf': [],\n",
       " 'chb02_34.edf': [],\n",
       " 'chb02_35.edf': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_seizure_events_from_txt(\"C:\\\\Users\\\\itama\\\\Desktop\\\\data analysis for neuroscience course\\\\Seizure_Onset_Prediction\\\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dbb3b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Loaded chb01_03.edf with 1 seizure intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Loaded chb01_04.edf with 1 seizure intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Loaded chb01_15.edf with 1 seizure intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Loaded chb01_16.edf with 1 seizure intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Loaded chb01_18.edf with 1 seizure intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Loaded chb01_21.edf with 1 seizure intervals\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded chb01_26.edf with 1 seizure intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Loaded chb02_05.edf with 0 seizure intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Loaded chb02_14.edf with 0 seizure intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Loaded chb02_16+.edf with 1 seizure intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Loaded chb02_19.edf with 1 seizure intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Loaded chb02_35.edf with 0 seizure intervals\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chb01_03.edf': {'raw': <RawEDF | chb01_03.edf, 22 x 921600 (3600.0 s), ~154.7 MiB, data loaded>,\n",
       "  'seizure_samples': [(766976, 777216)]},\n",
       " 'chb01_04.edf': {'raw': <RawEDF | chb01_04.edf, 22 x 921600 (3600.0 s), ~154.7 MiB, data loaded>,\n",
       "  'seizure_samples': [(375552, 382464)]},\n",
       " 'chb01_15.edf': {'raw': <RawEDF | chb01_15.edf, 22 x 921600 (3600.0 s), ~154.7 MiB, data loaded>,\n",
       "  'seizure_samples': [(443392, 453632)]},\n",
       " 'chb01_16.edf': {'raw': <RawEDF | chb01_16.edf, 22 x 921600 (3600.0 s), ~154.7 MiB, data loaded>,\n",
       "  'seizure_samples': [(259840, 272896)]},\n",
       " 'chb01_18.edf': {'raw': <RawEDF | chb01_18.edf, 22 x 921600 (3600.0 s), ~154.7 MiB, data loaded>,\n",
       "  'seizure_samples': [(440320, 463360)]},\n",
       " 'chb01_21.edf': {'raw': <RawEDF | chb01_21.edf, 22 x 921600 (3600.0 s), ~154.7 MiB, data loaded>,\n",
       "  'seizure_samples': [(83712, 107520)]},\n",
       " 'chb01_26.edf': {'raw': <RawEDF | chb01_26.edf, 22 x 595200 (2325.0 s), ~99.9 MiB, data loaded>,\n",
       "  'seizure_samples': [(476672, 502528)]},\n",
       " 'chb02_05.edf': {'raw': <RawEDF | chb02_05.edf, 22 x 921600 (3600.0 s), ~154.7 MiB, data loaded>,\n",
       "  'seizure_samples': []},\n",
       " 'chb02_14.edf': {'raw': <RawEDF | chb02_14.edf, 22 x 921600 (3600.0 s), ~154.7 MiB, data loaded>,\n",
       "  'seizure_samples': []},\n",
       " 'chb02_16+.edf': {'raw': <RawEDF | chb02_16+.edf, 22 x 921600 (3600.0 s), ~154.7 MiB, data loaded>,\n",
       "  'seizure_samples': [(760832, 781568)]},\n",
       " 'chb02_19.edf': {'raw': <RawEDF | chb02_19.edf, 22 x 921600 (3600.0 s), ~154.7 MiB, data loaded>,\n",
       "  'seizure_samples': [(862464, 864768)]},\n",
       " 'chb02_35.edf': {'raw': <RawEDF | chb02_35.edf, 22 x 921600 (3600.0 s), ~154.7 MiB, data loaded>,\n",
       "  'seizure_samples': []}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_load_edf_with_seizures(\"C:\\\\Users\\\\itama\\\\Desktop\\\\data analysis for neuroscience course\\\\Seizure_Onset_Prediction\\\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa56b9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Saved to: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\preprocessed\\chb01_03_preprocessed.npz\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Saved to: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\preprocessed\\chb01_04_preprocessed.npz\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Saved to: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\preprocessed\\chb01_15_preprocessed.npz\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Saved to: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\preprocessed\\chb01_16_preprocessed.npz\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Saved to: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\preprocessed\\chb01_18_preprocessed.npz\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Saved to: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\preprocessed\\chb01_21_preprocessed.npz\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\preprocessed\\chb01_26_preprocessed.npz\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Saved to: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\preprocessed\\chb02_05_preprocessed.npz\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Saved to: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\preprocessed\\chb02_14_preprocessed.npz\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Saved to: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\preprocessed\\chb02_16+_preprocessed.npz\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Saved to: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\preprocessed\\chb02_19_preprocessed.npz\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itama\\AppData\\Local\\Temp\\ipykernel_12904\\2455710421.py:6: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Saved to: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\preprocessed\\chb02_35_preprocessed.npz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess_and_save(\"C:\\\\Users\\\\itama\\\\Desktop\\\\data analysis for neuroscience course\\\\Seizure_Onset_Prediction\\\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbfc1388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmented and saved: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\segmented\\chb01_03_segmented.npz\n",
      "Segmented and saved: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\segmented\\chb01_04_segmented.npz\n",
      "Segmented and saved: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\segmented\\chb01_15_segmented.npz\n",
      "Segmented and saved: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\segmented\\chb01_16_segmented.npz\n",
      "Segmented and saved: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\segmented\\chb01_18_segmented.npz\n",
      "Segmented and saved: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\segmented\\chb01_21_segmented.npz\n",
      "Segmented and saved: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\segmented\\chb01_26_segmented.npz\n",
      "Segmented and saved: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\segmented\\chb02_05_segmented.npz\n",
      "Segmented and saved: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\segmented\\chb02_14_segmented.npz\n",
      "Segmented and saved: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\segmented\\chb02_16+_segmented.npz\n",
      "Segmented and saved: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\segmented\\chb02_19_segmented.npz\n",
      "Segmented and saved: C:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\data\\segmented\\chb02_35_segmented.npz\n"
     ]
    }
   ],
   "source": [
    "batch_segment_preprocessed(\"C:\\\\Users\\\\itama\\\\Desktop\\\\data analysis for neuroscience course\\\\Seizure_Onset_Prediction\\\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf350f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total, y_total = load_segmented_dataset(\"C:\\\\Users\\\\itama\\\\Desktop\\\\data analysis for neuroscience course\\\\Seizure_Onset_Prediction\\\\data\\\\segmented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea3034",
   "metadata": {},
   "source": [
    "Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a27053f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def downsample_majority(X, y, majority_label=0, minority_label=1, majority_n=1500):\n",
    "    \"\"\"\n",
    "    Downsamples the majority class and returns the balanced dataset.\n",
    "    \"\"\"\n",
    " \n",
    "    X_major = X[y == majority_label]\n",
    "    y_major = y[y == majority_label]\n",
    "    X_minor = X[y == minority_label]\n",
    "    y_minor = y[y == minority_label]\n",
    "\n",
    "\n",
    "    X_major_down, y_major_down = resample(\n",
    "        X_major, y_major,\n",
    "        replace=False,\n",
    "        n_samples=majority_n,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_balanced = np.concatenate([X_major_down, X_minor], axis=0)\n",
    "    y_balanced = np.concatenate([y_major_down, y_minor], axis=0)\n",
    "\n",
    "    return X_balanced, y_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dfafd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bal, y_bal = downsample_majority(X_total, y_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f8cb243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2.87991202e-20,  6.42969641e-06,  1.22599718e-05, ...,\n",
       "          1.56281909e-05,  1.14660171e-05,  5.43074258e-06],\n",
       "        [-1.01643954e-20, -1.56614291e-05, -2.92070716e-05, ...,\n",
       "          9.52223067e-06,  2.84919028e-06, -3.36021556e-06],\n",
       "        [-1.52465931e-20,  1.19023816e-06,  2.33426152e-06, ...,\n",
       "         -5.36879916e-06, -6.52776753e-06, -6.50054765e-06],\n",
       "        ...,\n",
       "        [-4.06575815e-20, -8.09525175e-05, -1.47461516e-04, ...,\n",
       "         -2.48980473e-05, -2.11648211e-05, -1.67908048e-05],\n",
       "        [-2.54109884e-20,  6.95159930e-06,  1.31081691e-05, ...,\n",
       "          3.11578356e-06,  1.20153036e-06,  8.49901912e-07],\n",
       "        [-1.69406589e-20, -3.64806395e-05, -6.70565824e-05, ...,\n",
       "         -2.73760954e-05, -2.99965436e-05, -3.18070190e-05]],\n",
       "\n",
       "       [[ 4.14498987e-05,  4.47206844e-05,  4.65753781e-05, ...,\n",
       "         -1.19632218e-05, -1.18090963e-07,  1.18764902e-05],\n",
       "        [ 9.43266886e-06,  8.44705847e-06,  7.52008485e-06, ...,\n",
       "          4.69829433e-05,  4.83797413e-05,  4.93955697e-05],\n",
       "        [-3.18680173e-05, -3.26720845e-05, -3.34333734e-05, ...,\n",
       "          9.64028397e-06,  1.04895168e-05,  1.16980993e-05],\n",
       "        ...,\n",
       "        [-3.47029461e-05, -3.22080588e-05, -3.08044833e-05, ...,\n",
       "          1.39545797e-06,  7.24017212e-06,  1.25461409e-05],\n",
       "        [ 1.41770674e-07,  2.35500562e-06,  4.24550478e-06, ...,\n",
       "          3.54198662e-05,  4.66131473e-05,  5.98764633e-05],\n",
       "        [-1.49420812e-05, -1.96807490e-05, -2.45980994e-05, ...,\n",
       "          4.14562841e-05,  3.90967507e-05,  3.33721182e-05]],\n",
       "\n",
       "       [[-2.02085088e-06, -1.03488576e-05, -1.89615417e-05, ...,\n",
       "         -6.01083848e-06, -6.49407200e-06, -6.56091023e-06],\n",
       "        [-8.18188182e-06, -1.07754545e-05, -1.05674875e-05, ...,\n",
       "         -5.49850486e-07, -3.86819539e-06, -7.60625569e-06],\n",
       "        [-5.07659624e-06, -2.33743620e-06,  1.36887610e-06, ...,\n",
       "          1.16018721e-05,  1.21158084e-05,  1.23857743e-05],\n",
       "        ...,\n",
       "        [-1.23342103e-05, -8.34312242e-06, -5.26082769e-06, ...,\n",
       "          7.75296702e-06,  9.86363052e-06,  1.19920354e-05],\n",
       "        [ 2.05722876e-06,  4.48352751e-06,  7.56935281e-06, ...,\n",
       "          2.17656245e-05,  1.12770028e-05,  1.44611078e-06],\n",
       "        [-3.19018742e-05, -2.96834265e-05, -2.50670498e-05, ...,\n",
       "          2.60911881e-05,  2.74966162e-05,  2.69057553e-05]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.93382962e-04,  1.96594925e-04,  1.96766490e-04, ...,\n",
       "         -4.41865519e-05, -4.33629870e-05, -4.53666383e-05],\n",
       "        [-2.67683770e-04, -2.59114814e-04, -2.55915018e-04, ...,\n",
       "          3.86667270e-05,  3.14738916e-05,  2.79993735e-05],\n",
       "        [ 8.25407683e-06,  1.77049738e-06, -9.84770308e-08, ...,\n",
       "          2.56599639e-06,  4.32142370e-06,  2.76266122e-06],\n",
       "        ...,\n",
       "        [-3.57456557e-05, -3.57583050e-05, -3.55283428e-05, ...,\n",
       "         -8.73154323e-06, -6.28156223e-06, -4.71976036e-06],\n",
       "        [-1.55613513e-05, -1.92489417e-05, -2.26198740e-05, ...,\n",
       "          3.19386188e-05,  2.69044904e-05,  2.08886303e-05],\n",
       "        [-5.04474321e-05, -3.86502203e-05, -3.76529961e-05, ...,\n",
       "         -9.74960537e-05, -1.28346963e-04, -1.51201634e-04]],\n",
       "\n",
       "       [[-9.62014207e-05, -1.11772182e-04, -1.28689708e-04, ...,\n",
       "          3.92266160e-05,  4.94204154e-05,  6.24604774e-05],\n",
       "        [ 1.97660094e-04,  2.05868197e-04,  2.16069056e-04, ...,\n",
       "         -8.74027708e-05, -8.34984909e-05, -7.66631469e-05],\n",
       "        [-1.49670517e-05, -1.87671724e-05, -2.42701145e-05, ...,\n",
       "          1.55229064e-05,  1.15697680e-05,  6.12710661e-06],\n",
       "        ...,\n",
       "        [-6.49028620e-06, -6.90718596e-06, -5.10671841e-06, ...,\n",
       "          3.21231102e-05,  2.98937023e-05,  2.55581034e-05],\n",
       "        [ 3.61679740e-05,  3.21588794e-05,  2.93333136e-05, ...,\n",
       "         -3.24129185e-06, -1.28817306e-06,  5.48728749e-07],\n",
       "        [ 8.06768306e-05,  8.21533531e-05,  8.26265969e-05, ...,\n",
       "         -2.29440991e-05, -2.20373825e-05, -2.08911193e-05]],\n",
       "\n",
       "       [[-4.93870742e-05, -5.39169594e-05, -5.72121501e-05, ...,\n",
       "          6.32538173e-05,  3.70147786e-05, -3.72694497e-20],\n",
       "        [ 2.86160654e-05,  3.28479902e-05,  3.95865729e-05, ...,\n",
       "         -9.41988201e-05, -5.44067343e-05, -4.06575815e-20],\n",
       "        [-2.42095226e-06, -1.05072567e-05, -1.99648465e-05, ...,\n",
       "          6.26320071e-05,  3.54247207e-05,  6.77626358e-21],\n",
       "        ...,\n",
       "        [-4.18107366e-06, -4.55152214e-06, -5.59015206e-06, ...,\n",
       "          7.54622668e-06,  3.85372594e-06,  6.77626358e-21],\n",
       "        [ 1.46179535e-05,  8.81400907e-06,  4.05592117e-06, ...,\n",
       "          1.25347281e-05,  6.87231211e-06, -5.92923063e-21],\n",
       "        [-1.62512877e-04, -1.61612751e-04, -1.50843865e-04, ...,\n",
       "          1.18256928e-06,  7.98086785e-07, -2.71050543e-20]]],\n",
       "      shape=(41913, 17, 512))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d454adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def specificity_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = cm[0, 0]\n",
    "    fp = cm[0, 1]\n",
    "    return tn / (tn + fp + 1e-10)\n",
    "\n",
    "def train_ml(X_total, y_total):\n",
    "    \"\"\"\n",
    "    Trains classical ML models (Logistic Regression, Random Forest, SVM) on flattened EEG data.\n",
    "    \"\"\"\n",
    "    X_total_flat = X_total.reshape(X_total.shape[0], -1)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X_total_flat, y_total, test_size=0.3, stratify=y_total, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        # 'LogisticRegression': LogisticRegression(class_weight=\"balanced\", max_iter=1000),\n",
    "        # 'RandomForest': RandomForestClassifier(n_estimators=100),\n",
    "        'SVM': SVC()\n",
    "    }\n",
    "\n",
    "    scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall',\n",
    "        'f1': 'f1'\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    trained_models = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n==== {name} ====\")\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('clf', model)\n",
    "        ])\n",
    "\n",
    "        cv_results = cross_validate(pipeline, X_train, y_train, cv=cv, scoring=scoring)\n",
    "        for metric in scoring:\n",
    "            scores = cv_results[f'test_{metric}']\n",
    "            print(f\"{metric.capitalize()} (CV): {scores.mean():.4f} ± {scores.std():.4f}\")\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        trained_models[name] = pipeline  # store fitted model\n",
    "        y_val_pred = pipeline.predict(X_val)\n",
    "\n",
    "        acc = accuracy_score(y_val, y_val_pred)\n",
    "        prec = precision_score(y_val, y_val_pred)\n",
    "        rec = recall_score(y_val, y_val_pred)\n",
    "        spec = specificity_score(y_val, y_val_pred)\n",
    "        f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "        print(f\"\\nValidation Set Performance:\")\n",
    "        print(f\"Accuracy:    {acc:.4f}\")\n",
    "        print(f\"Precision:   {prec:.4f}\")\n",
    "        print(f\"Recall:      {rec:.4f}\")\n",
    "        print(f\"Specificity: {spec:.4f}\")\n",
    "        print(f\"F1 Score:    {f1:.4f}\")\n",
    "\n",
    "        y_test_pred = pipeline.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_test_pred)\n",
    "        prec = precision_score(y_test, y_test_pred)\n",
    "        rec = recall_score(y_test, y_test_pred)\n",
    "        spec = specificity_score(y_test, y_test_pred)\n",
    "        f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "        print(f\"\\nTest Set Performance:\")\n",
    "        print(f\"Accuracy:    {acc:.4f}\")\n",
    "        print(f\"Precision:   {prec:.4f}\")\n",
    "        print(f\"Recall:      {rec:.4f}\")\n",
    "        print(f\"Specificity: {spec:.4f}\")\n",
    "        print(f\"F1 Score:    {f1:.4f}\")\n",
    "    return trained_models, (X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39ffe398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== SVM ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (CV): 0.9871 ± 0.0001\n",
      "Precision (CV): 0.0000 ± 0.0000\n",
      "Recall (CV): 0.0000 ± 0.0000\n",
      "F1 (CV): 0.0000 ± 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Set Performance:\n",
      "Accuracy:    0.9871\n",
      "Precision:   0.0000\n",
      "Recall:      0.0000\n",
      "Specificity: 1.0000\n",
      "F1 Score:    0.0000\n",
      "\n",
      "Test Set Performance:\n",
      "Accuracy:    0.9871\n",
      "Precision:   0.0000\n",
      "Recall:      0.0000\n",
      "Specificity: 1.0000\n",
      "F1 Score:    0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "trained_models, splits = train_ml(X_total, y_total)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16fcc524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the balanced data\n",
    "np.savez_compressed(\"balanced_dataset1.npz\", X=X_bal, y=y_bal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f14acf",
   "metadata": {},
   "source": [
    "#Optimizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5cd74e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparamter tuning with pca\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(class_weight='balanced', max_iter=1000),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'SVM': SVC(class_weight='balanced')}\n",
    "\n",
    "param_grid = {\n",
    "    'LogisticRegression': {'pca__n_components': [10, 20, 30, 50],'clf__C': [0.01, 0.1, 1, 10], 'clf__penalty': ['l2'], 'clf__solver': ['lbfgs']},\n",
    "    'RandomForest': {'pca__n_components': [10, 20, 30, 50],'clf__n_estimators': [100,200], 'clf__max_depth': [None, 10, 20]},\n",
    "    'SVM': {'pca__n_components': [10, 20, 30, 50],'clf__C': [0.1,1,10], 'clf__kernel': ['rbf', 'linear'], 'clf__gamma': ['scale', 'auto']}}\n",
    "\n",
    "\n",
    "def train_ml_optimized(X_total, y_total):\n",
    "    \"\"\"\n",
    "    Here is the optimized training function for the models\n",
    "    \"\"\"\n",
    "    X_total_flat = X_total.reshape(X_total.shape[0], -1)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X_total_flat, y_total, test_size=0.3, stratify=y_total, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for name in models:\n",
    "        print(f\"\\n==== {name} ====\")\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('pca', PCA()),\n",
    "            ('clf', models[name])\n",
    "        ])\n",
    "        grid = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid[name],\n",
    "            cv=cv,\n",
    "            scoring='f1',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_model = grid.best_estimator_\n",
    "        print(f\"Best Params: {grid.best_params_}\")\n",
    "\n",
    "        y_val_pred = best_model.predict(X_val)\n",
    "        print(\"\\nValidation Set Performance:\")\n",
    "        print(f\"Accuracy:    {accuracy_score(y_val, y_val_pred):.4f}\")\n",
    "        print(f\"Precision:   {precision_score(y_val, y_val_pred):.4f}\")\n",
    "        print(f\"Recall:      {recall_score(y_val, y_val_pred):.4f}\")\n",
    "        print(f\"Specificity: {specificity_score(y_val, y_val_pred):.4f}\")\n",
    "        print(f\"F1 Score:    {f1_score(y_val, y_val_pred):.4f}\")\n",
    "\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        print(\"\\nTest Set Performance:\")\n",
    "        print(f\"Accuracy:    {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "        print(f\"Precision:   {precision_score(y_test, y_test_pred):.4f}\")\n",
    "        print(f\"Recall:      {recall_score(y_test, y_test_pred):.4f}\")\n",
    "        print(f\"Specificity: {specificity_score(y_test, y_test_pred):.4f}\")\n",
    "        print(f\"F1 Score:    {f1_score(y_test, y_test_pred):.4f}\")\n",
    "\n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "377513ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== LogisticRegression ====\n",
      "Best Params: {'clf__C': 0.1, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs', 'pca__n_components': 20}\n",
      "\n",
      "Validation Set Performance:\n",
      "Accuracy:    0.6242\n",
      "Precision:   0.3300\n",
      "Recall:      0.4074\n",
      "Specificity: 0.7022\n",
      "F1 Score:    0.3646\n",
      "\n",
      "Test Set Performance:\n",
      "Accuracy:    0.5993\n",
      "Precision:   0.2857\n",
      "Recall:      0.3457\n",
      "Specificity: 0.6903\n",
      "F1 Score:    0.3128\n",
      "\n",
      "==== RandomForest ====\n",
      "Best Params: {'clf__max_depth': None, 'clf__n_estimators': 200, 'pca__n_components': 50}\n",
      "\n",
      "Validation Set Performance:\n",
      "Accuracy:    0.9020\n",
      "Precision:   0.8493\n",
      "Recall:      0.7654\n",
      "Specificity: 0.9511\n",
      "F1 Score:    0.8052\n",
      "\n",
      "Test Set Performance:\n",
      "Accuracy:    0.9283\n",
      "Precision:   0.9155\n",
      "Recall:      0.8025\n",
      "Specificity: 0.9735\n",
      "F1 Score:    0.8553\n",
      "\n",
      "==== SVM ====\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_ml_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_bal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_bal\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mtrain_ml_optimized\u001b[39m\u001b[34m(X_total, y_total)\u001b[39m\n\u001b[32m     26\u001b[39m pipeline = Pipeline([\n\u001b[32m     27\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mscaler\u001b[39m\u001b[33m'\u001b[39m, StandardScaler()),\n\u001b[32m     28\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mpca\u001b[39m\u001b[33m'\u001b[39m, PCA()),\n\u001b[32m     29\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mclf\u001b[39m\u001b[33m'\u001b[39m, models[name])\n\u001b[32m     30\u001b[39m ])\n\u001b[32m     31\u001b[39m grid = GridSearchCV(\n\u001b[32m     32\u001b[39m     pipeline,\n\u001b[32m     33\u001b[39m     param_grid[name],\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     37\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m best_model = grid.best_estimator_\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest Params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid.best_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\itama\\Desktop\\data analysis for neuroscience course\\Seizure_Onset_Prediction\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_ml_optimized(X_bal, y_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd336cf5",
   "metadata": {},
   "source": [
    "Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d0d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "\n",
    "def _get_scores_for_binary_roc(model, X):\n",
    "    \"\"\"\n",
    "    Returns a continuous score for the positive class:\n",
    "    - decision_function if available\n",
    "    - otherwise the probability for class 1 (or the 'positive' label if provided by caller)\n",
    "    \"\"\"\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        s = model.decision_function(X)\n",
    "        # Some estimators return shape (n_samples, n_classes). Reduce to positive class if binary.\n",
    "        if s.ndim == 2 and s.shape[1] == 2:\n",
    "            s = s[:, 1]\n",
    "        return s\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        proba = model.predict_proba(X)\n",
    "        # assume binary, take probability of the 2nd column (positive class)\n",
    "        if proba.shape[1] == 2:\n",
    "            return proba[:, 1]\n",
    "    raise ValueError(\"Model must support decision_function or predict_proba for ROC.\")\n",
    "\n",
    "# Confusion Matrix ----\n",
    "def plot_confusion_matrix_svm(y_true, y_pred, labels=None, normalize='true', title=\"SVM Confusion Matrix\"):\n",
    "    \"\"\"\n",
    "    normalize: {'true','pred','all', None} mirrors sklearn\n",
    "    labels: optional sequence of label names in the order you want to display\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels, normalize=normalize)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels if labels is not None else None)\n",
    "    fig, ax = plt.subplots(figsize=(5.5, 5))\n",
    "    disp.plot(ax=ax, cmap=\"Blues\", colorbar=True, values_format=\".2f\" if normalize else \"d\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ROC Curve + AUC (binary) ----\n",
    "def plot_roc_auc_svm(y_true, y_score, pos_label=1, title=\"SVM ROC Curve\"):\n",
    "    \"\"\"\n",
    "    y_score: continuous score for the positive class (from decision_function or predict_proba[:,1])\n",
    "    pos_label: which label counts as the positive class in y_true\n",
    "    \"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=pos_label)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(5.5, 5))\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=f\"AUC = {roc_auc:.3f}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", linewidth=1)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# One-sample visualization (feature heatmap) ----\n",
    "def plot_sample_feature_heatmap(sample_features, channels=18, bands=8,\n",
    "                                channel_names=None, band_names=None,\n",
    "                                title=\"One Sample: Channels × Bands Feature Heatmap\",\n",
    "                                vmin=None, vmax=None,\n",
    "                                x_tick_step=None):\n",
    "    \"\"\"\n",
    "    Visualize a single (channels × bands) feature vector as a heatmap.\n",
    "\n",
    "    sample_features: 1D array-like, length = channels*bands\n",
    "    channels: number of channels (rows)\n",
    "    bands: number of bands (columns)\n",
    "    x_tick_step: show an x-axis label every this many columns (default=None = show all)\n",
    "    \"\"\"\n",
    "    sample_features = np.asarray(sample_features).ravel()\n",
    "    expected = channels * bands\n",
    "    if sample_features.size != expected:\n",
    "        raise ValueError(f\"Expected {expected} features, got {sample_features.size}.\")\n",
    "\n",
    "    mat = sample_features.reshape(channels, bands)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    im = plt.imshow(mat, aspect=\"auto\", interpolation=\"nearest\", vmin=vmin, vmax=vmax)\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label(\"Feature value\", rotation=270, labelpad=12)\n",
    "\n",
    "    if band_names is None:\n",
    "        band_names = [f\"Band {i+1}\" for i in range(bands)]\n",
    "    if channel_names is None:\n",
    "        channel_names = [f\"Ch {i+1}\" for i in range(channels)]\n",
    "\n",
    "    # control tick step\n",
    "    if x_tick_step is None:\n",
    "        x_ticks = np.arange(bands)\n",
    "    else:\n",
    "        x_ticks = np.arange(0, bands, x_tick_step)\n",
    "\n",
    "    plt.xticks(ticks=x_ticks, labels=[band_names[i] for i in x_ticks], rotation=45, ha=\"right\")\n",
    "    plt.yticks(ticks=np.arange(channels), labels=channel_names)\n",
    "    plt.xlabel(\"Frequency Bands\")\n",
    "    plt.ylabel(\"Channels\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# SVM feature weights heatmap ----\n",
    "def plot_svm_feature_weights(svm_model, channels=18, bands=8,\n",
    "                             channel_names=None, band_names=None,\n",
    "                             use_abs=True,\n",
    "                             title=\"SVM Feature Weights (Channels × Bands)\"):\n",
    "    \"\"\"\n",
    "    Visualize the learned weights for each of the 144 features (18×8) from a linear SVM.\n",
    "    - For multiclass (One-vs-Rest), averages |weights| across classes by default (use_abs=True).\n",
    "    - For binary, uses coef_[0].\n",
    "    \"\"\"\n",
    "    if not hasattr(svm_model, \"coef_\"):\n",
    "        raise ValueError(\"This visualization requires a linear SVM with a 'coef_' attribute (e.g., LinearSVC or SVC(kernel='linear')).\")\n",
    "\n",
    "    coefs = svm_model.coef_\n",
    "    # coefs shape: (n_classes, n_features)\n",
    "    if coefs.ndim == 1:\n",
    "        w = coefs\n",
    "    else:\n",
    "        if coefs.shape[0] == 1:\n",
    "            w = coefs[0]\n",
    "        else:\n",
    "            # multiclass: aggregate across classes\n",
    "            w = np.mean(np.abs(coefs), axis=0) if use_abs else np.mean(coefs, axis=0)\n",
    "\n",
    "    w = np.asarray(w).ravel()\n",
    "    expected = channels * bands\n",
    "    if w.size != expected:\n",
    "        raise ValueError(f\"Expected {expected} weights (channels×bands), got {w.size}.\")\n",
    "\n",
    "    W = w.reshape(channels, bands)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    im = plt.imshow(W, aspect=\"auto\", interpolation=\"nearest\")\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label(\"Weight\" + (\" (|coef| mean)\" if coefs.ndim == 2 and coefs.shape[0] > 1 and use_abs else \"\"), rotation=270, labelpad=12)\n",
    "\n",
    "    if band_names is None:\n",
    "        band_names = [f\"Band {i+1}\" for i in range(bands)]\n",
    "    if channel_names is None:\n",
    "        channel_names = [f\"Ch {i+1}\" for i in range(channels)]\n",
    "\n",
    "    plt.xticks(ticks=np.arange(bands), labels=band_names, rotation=45, ha=\"right\")\n",
    "    plt.yticks(ticks=np.arange(channels), labels=channel_names)\n",
    "    plt.xlabel(\"Frequency Bands\")\n",
    "    plt.ylabel(\"Channels\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def top_k_svm_features(svm_model, k=10, feature_names=None):\n",
    "    \"\"\"\n",
    "    Returns indices and weights for the top-k features by absolute weight (binary or averaged multiclass).\n",
    "    \"\"\"\n",
    "    if not hasattr(svm_model, \"coef_\"):\n",
    "        raise ValueError(\"Model has no coef_. Use a linear SVM.\")\n",
    "    coefs = svm_model.coef_\n",
    "    if coefs.ndim == 2 and coefs.shape[0] > 1:\n",
    "        w = np.mean(np.abs(coefs), axis=0)\n",
    "    else:\n",
    "        w = coefs.ravel()\n",
    "    order = np.argsort(np.abs(w))[::-1][:k]\n",
    "    names = [feature_names[i] if feature_names is not None else f\"f{i}\" for i in order]\n",
    "    return list(zip(names, w[order]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = trained_models['SVM']\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# 1) Confusion matrix\n",
    "labels = getattr(svm_model, \"classes_\", None)\n",
    "plot_confusion_matrix_svm(y_test, y_pred, labels=labels, normalize='true')\n",
    "\n",
    "# 2) ROC + AUC (binary)\n",
    "y_score = _get_scores_for_binary_roc(svm_model, X_test)\n",
    "# Choose the positive label explicitly if your labels aren’t {0,1}\n",
    "pos_label = 1 if labels is None else labels[1] if len(labels) == 2 else 1\n",
    "\n",
    "plot_roc_auc_svm(y_test, y_score, pos_label=pos_label)\n",
    "\n",
    "# 3) One-sample feature heatmap (pick any sample)\n",
    "plot_sample_feature_heatmap(X_test[0],\n",
    "                            channels=17, bands=512,\n",
    "                            x_tick_step=50,  # label every 10 columns\n",
    "                            channel_names=[f\"Ch {i+1}\" for i in range(17)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d50ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) SVM weights (144 features → 18×8)\n",
    "# plot_svm_feature_weights(svm_model, channels=18, bands=8,\n",
    "#                          channel_names=[f\"Ch {i+1}\" for i in range(17)],\n",
    "#                          band_names=[f\"Band {i+1}\" for i in range(512)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
